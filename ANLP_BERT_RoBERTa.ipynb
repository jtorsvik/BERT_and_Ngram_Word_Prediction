{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db006ea",
   "metadata": {},
   "source": [
    "# Advanced Natural Lanugage Processing\n",
    "\n",
    "## Pre-trained BERT and RoBERTa-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af5e4fe-a801-4f50-a4ab-25e536dd9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General working tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Useful ML Tools\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "095fd09c-e042-45bf-b97f-92edaaec3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "parentdir = \"C:\\\\Users\\Joakim Torsvik\\Downloads\\MSc Data Science\\Advanced NLP\\Week 2 - N-grams\\sentence-completion\"\n",
    "test_data = pd.read_csv(os.path.join(parentdir, 'testing_data.csv'),index_col=0)\n",
    "test_answer = pd.read_csv(os.path.join(parentdir, 'test_answer.csv'),index_col=0).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae33ce",
   "metadata": {},
   "source": [
    "## BERT and RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efacd50a-8a7d-4cc3-b693-5333d2035eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14de6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {0:'a', 1:'b', 2:'c', 3:'d', 4:'e'}\n",
    "\n",
    "def get_options_indices(tokenizer, prefix, options):\n",
    "    \n",
    "    \"\"\"Converting options' text into id of the tokenizer\n",
    "    Args:\n",
    "    - tokenizer: PretrainedTokenizer\n",
    "    - options: list\n",
    "    Return: indices of each option's text (list)\"\"\"\n",
    "    \n",
    "    indices = [tokenizer(option)['input_ids'][1:-1] for option in options]\n",
    "    for i, option in enumerate(options):\n",
    "        if prefix + option in tokenizer.vocab.keys():\n",
    "            indices[i] = [tokenizer.convert_tokens_to_ids(prefix+option)]\n",
    "    return indices\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "\n",
    "class pretrained_model_tester():\n",
    "    \n",
    "    def __init__(self, test_df, model_checkpoint):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_checkpoint).to(device)\n",
    "        self.model.eval()\n",
    "        self.test_data = test_df.copy()\n",
    "        # RoBERTa\n",
    "        if 'roberta' in model_checkpoint:\n",
    "            self.test_data.question = self.test_data.question.str.replace('_____', '<mask>')\n",
    "            self.embedding_weight = self.model.roberta.embeddings.word_embeddings.weight\n",
    "            self.prefix = 'Ä ' \n",
    "        else: # BERT\n",
    "            self.test_data.question = self.test_data.question.str.replace('_____', '[MASK]')\n",
    "            self.embedding_weight = self.model.bert.embeddings.word_embeddings.weight\n",
    "            self.prefix = ''\n",
    "\n",
    "    def predict(self, question, options, result_method, pooling_method):\n",
    "        \n",
    "        \"\"\"Perform sentence splitting, tokenizing, applying model and get result.\n",
    "        Args:\n",
    "        - question: string\n",
    "            text with masked token\n",
    "        - options: list of string\n",
    "            option to be chosen\n",
    "        - result_method: string\n",
    "            `base_only` (use only the first token of the option) or `all` (use every token)\n",
    "        - pooling_method: string\n",
    "            `sum` (summing all the embedding of tokens together) or `mean` (averaging all the embedding of tokens together)\n",
    "        Return: index of the option chosen (int)\"\"\"\n",
    "        \n",
    "        # tokenizing\n",
    "        inputs = self.tokenizer(question,return_tensors='pt')\n",
    "        # move to gpu if available\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        # misc\n",
    "        masked_index = np.where((inputs['input_ids'] == self.tokenizer.mask_token_id).cpu())[1][0]\n",
    "        options_indices = get_options_indices(self.tokenizer, self.prefix, options)\n",
    "        \n",
    "        # get result\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)[0]\n",
    "            if result_method == 'base_only':\n",
    "                options_indices = [option[0] for option in options_indices]\n",
    "                outputs=outputs[:, masked_index, options_indices]\n",
    "                return torch.argmax(outputs).item(), np.array(outputs)[0]\n",
    "            \n",
    "            elif result_method == 'all':\n",
    "                predicted_index = torch.argmax(outputs[0, masked_index]).item()\n",
    "                predicted_embedding = self.embedding_weight[predicted_index,:]\n",
    "                similarity = []\n",
    "                \n",
    "                for indices in options_indices:\n",
    "                    if pooling_method == 'mean':\n",
    "                        similarity.append(cos(predicted_embedding,self.embedding_weight[indices,:].mean(axis=0)).item())\n",
    "                    \n",
    "                    elif pooling_method == 'max':\n",
    "                        similarity.append(cos(predicted_embedding,self.embedding_weight[indices,:].max(axis=0)[0]).item())\n",
    "                    \n",
    "                    elif pooling_method == 'min':\n",
    "                        similarity.append(cos(predicted_embedding,self.embedding_weight[indices,:].min(axis=0)[0]).item())\n",
    "                    \n",
    "                    else:\n",
    "                        raise TypeError('pooling_method must be `mean`, `max` or `min` when result_method is `all`')\n",
    "                return np.argmax(similarity), np.array(similarity)\n",
    "            else:\n",
    "                raise TypeError('result_method must be either `base_only` or `all`')\n",
    "    \n",
    "    def batch_predict(self, result_method, pooling_method='sum'):\n",
    "        \n",
    "        \"\"\" Perform prediction on the whole test df\n",
    "\n",
    "        Arguments:\n",
    "        - result_method: string\n",
    "            `base_only` (use only the first token of the option) or `all` (use every token)\n",
    "        - pooling_method: string\n",
    "            `sum` (summing all the embedding of tokens together) or `mean` (averaging all the embedding of tokens together)\n",
    "\n",
    "        Return: answers of the questions (pandas series)\"\"\"\n",
    "        \n",
    "        result = []\n",
    "        all_preds = []\n",
    "        for index, row in self.test_data.iterrows():\n",
    "            question = row[0]\n",
    "            options = row[1:].tolist()\n",
    "            predicted_ind, predictions = self.predict(question, options, result_method, pooling_method)\n",
    "            result.append(answers[predicted_ind])\n",
    "            all_preds.append(predictions)\n",
    "        return pd.Series(result, index=test_data.index), pd.Series(all_preds, index=test_data.index)\n",
    "\n",
    "def get_accuracy(prediction, labels):\n",
    "    return sum(prediction==labels) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "010d7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'model_checkpoints': ['bert-base-uncased', 'bert-base-cased', 'bert-large-uncased',\n",
    "                                'bert-large-cased', 'roberta-base', 'roberta-large'],\n",
    "          'result_method':['base_only', 'all'],\n",
    "          'pooling_method':['max', 'min', 'mean']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad8611e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "all_predictions = []\n",
    "\n",
    "for checkpoint in params['model_checkpoints']:\n",
    "    pretrained_model = pretrained_model_tester(test_data, checkpoint)\n",
    "    for method in params['result_method']:\n",
    "        if method == 'base_only':\n",
    "            predictions, all_preds = pretrained_model.batch_predict(method, None)\n",
    "            res.append([checkpoint, method, None, round(get_accuracy(predictions, test_answer) * 100, 3)])\n",
    "            all_predictions.append(all_preds)\n",
    "        else:\n",
    "            for pool in params['pooling_method']:\n",
    "                predictions, all_preds = pretrained_model.batch_predict(method, pool)\n",
    "                res.append([checkpoint, method, pool, round(get_accuracy(predictions, test_answer) * 100, 3)])\n",
    "                all_predictions.append(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ca5f2011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_checkpoints</th>\n",
       "      <th>result_method</th>\n",
       "      <th>pooling_method</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>base_only</td>\n",
       "      <td>None</td>\n",
       "      <td>75.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>all</td>\n",
       "      <td>max</td>\n",
       "      <td>49.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>all</td>\n",
       "      <td>min</td>\n",
       "      <td>45.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>all</td>\n",
       "      <td>mean</td>\n",
       "      <td>47.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>base_only</td>\n",
       "      <td>None</td>\n",
       "      <td>70.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>all</td>\n",
       "      <td>max</td>\n",
       "      <td>52.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>all</td>\n",
       "      <td>min</td>\n",
       "      <td>54.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>all</td>\n",
       "      <td>mean</td>\n",
       "      <td>55.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>base_only</td>\n",
       "      <td>None</td>\n",
       "      <td>78.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>all</td>\n",
       "      <td>max</td>\n",
       "      <td>53.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>all</td>\n",
       "      <td>min</td>\n",
       "      <td>52.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>all</td>\n",
       "      <td>mean</td>\n",
       "      <td>55.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>base_only</td>\n",
       "      <td>None</td>\n",
       "      <td>76.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>all</td>\n",
       "      <td>max</td>\n",
       "      <td>56.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>all</td>\n",
       "      <td>min</td>\n",
       "      <td>57.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>all</td>\n",
       "      <td>mean</td>\n",
       "      <td>58.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>base_only</td>\n",
       "      <td>None</td>\n",
       "      <td>71.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>all</td>\n",
       "      <td>max</td>\n",
       "      <td>54.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>all</td>\n",
       "      <td>min</td>\n",
       "      <td>56.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>all</td>\n",
       "      <td>mean</td>\n",
       "      <td>56.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>base_only</td>\n",
       "      <td>None</td>\n",
       "      <td>76.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>all</td>\n",
       "      <td>max</td>\n",
       "      <td>55.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>all</td>\n",
       "      <td>min</td>\n",
       "      <td>55.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>all</td>\n",
       "      <td>mean</td>\n",
       "      <td>57.596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_checkpoints result_method pooling_method  accuracy\n",
       "0    bert-base-uncased     base_only           None    75.000\n",
       "1    bert-base-uncased           all            max    49.038\n",
       "2    bert-base-uncased           all            min    45.192\n",
       "3    bert-base-uncased           all           mean    47.500\n",
       "4      bert-base-cased     base_only           None    70.192\n",
       "5      bert-base-cased           all            max    52.692\n",
       "6      bert-base-cased           all            min    54.904\n",
       "7      bert-base-cased           all           mean    55.000\n",
       "8   bert-large-uncased     base_only           None    78.846\n",
       "9   bert-large-uncased           all            max    53.942\n",
       "10  bert-large-uncased           all            min    52.019\n",
       "11  bert-large-uncased           all           mean    55.000\n",
       "12    bert-large-cased     base_only           None    76.250\n",
       "13    bert-large-cased           all            max    56.058\n",
       "14    bert-large-cased           all            min    57.788\n",
       "15    bert-large-cased           all           mean    58.846\n",
       "16        roberta-base     base_only           None    71.346\n",
       "17        roberta-base           all            max    54.712\n",
       "18        roberta-base           all            min    56.442\n",
       "19        roberta-base           all           mean    56.346\n",
       "20       roberta-large     base_only           None    76.731\n",
       "21       roberta-large           all            max    55.288\n",
       "22       roberta-large           all            min    55.481\n",
       "23       roberta-large           all           mean    57.596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.DataFrame(res, columns=['model_checkpoints', 'result_method', 'pooling_method', 'accuracy'])\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9f2a3bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model_checkpoints'>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.iloc[[8, 20]].plot.bar(x='model_checkpoints', y='accuracy', color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d19ef",
   "metadata": {},
   "source": [
    "The two best performing models are the ***large, uncased BERT*** and the ***large RoBERTa***. Let's compare the results from these two. First I want to extract the predictions from these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "dc4e7fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_checkpoints</th>\n",
       "      <th>bert</th>\n",
       "      <th>roberta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.77451825, -6.463148, 7.653578, -2.294808, 7...</td>\n",
       "      <td>[50.684612, 38.211086, 58.9898, 50.202072, 56....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-4.147023, 3.2802274, -1.8816494, -4.5027246,...</td>\n",
       "      <td>[48.49562, 53.062046, 48.574924, 46.047962, 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.097667314, 2.1758933, 3.1693223, 8.405982, ...</td>\n",
       "      <td>[51.145363, 52.572147, 47.3882, 56.167118, 39....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.85072356, 4.1159883, 15.790798, 1.5753299,...</td>\n",
       "      <td>[43.752407, 47.866486, 63.273304, 47.514767, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.4967327, 7.2874427, 3.972897, 15.980728, -0...</td>\n",
       "      <td>[48.99263, 51.783737, 47.79437, 61.866062, 42....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_checkpoints                                               bert  \\\n",
       "0                  [0.77451825, -6.463148, 7.653578, -2.294808, 7...   \n",
       "1                  [-4.147023, 3.2802274, -1.8816494, -4.5027246,...   \n",
       "2                  [0.097667314, 2.1758933, 3.1693223, 8.405982, ...   \n",
       "3                  [-0.85072356, 4.1159883, 15.790798, 1.5753299,...   \n",
       "4                  [2.4967327, 7.2874427, 3.972897, 15.980728, -0...   \n",
       "\n",
       "model_checkpoints                                            roberta  \n",
       "0                  [50.684612, 38.211086, 58.9898, 50.202072, 56....  \n",
       "1                  [48.49562, 53.062046, 48.574924, 46.047962, 55...  \n",
       "2                  [51.145363, 52.572147, 47.3882, 56.167118, 39....  \n",
       "3                  [43.752407, 47.866486, 63.273304, 47.514767, 4...  \n",
       "4                  [48.99263, 51.783737, 47.79437, 61.866062, 42....  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.DataFrame(np.array(all_predictions)[[8, 20]], index=result['model_checkpoints'].iloc[[8, 20]]).transpose()\n",
    "preds.rename(columns={'bert-large-uncased':'bert', 'roberta-large':'roberta'}, inplace=True)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a6f182dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = preds['bert'].values\n",
    "roberta = preds['roberta'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01db3ba",
   "metadata": {},
   "source": [
    "Changing the letter-values of the answers with their index values corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "67a4b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = test_answer.copy()\n",
    "\n",
    "for k, v in answers.items():\n",
    "    ans.replace(v, k, inplace=True)\n",
    "ans = ans.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b6bc5",
   "metadata": {},
   "source": [
    "Creating lists which show where each model answered correct or incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "26a81dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7884615384615384\n",
      "0.7673076923076924\n"
     ]
    }
   ],
   "source": [
    "bert_preds = [1 if ans[i] == np.argmax(bert[i]) else 0 for i in range(len(ans))]\n",
    "roberta_preds = [1 if ans[i] == np.argmax(roberta[i]) else 0 for i in range(len(ans))]\n",
    "\n",
    "# Just to test if it is correct\n",
    "print(sum(bert_preds) / len(bert_preds))\n",
    "print(sum(roberta_preds) / len(roberta_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae6b69",
   "metadata": {},
   "source": [
    "They still have the same accuracy.\n",
    "\n",
    "Now, let's look at how many questions they answered similar to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f56fa48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0 % predictions correct by both models.\n",
      "15.576923076923077 % predictions correct by only one model.\n",
      "14.423076923076922 % predictions incorrect by both models.\n"
     ]
    }
   ],
   "source": [
    "comparison = [(bert_preds[i] + roberta_preds[i])/2 for i in range(len(bert_preds))]\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(range(len(bert_preds)), sorted(comparison, reverse=True))\n",
    "plt.title(\"Comparison of answers - BERT vs. RoBERTa\")\n",
    "plt.xlabel(\"Questions\")\n",
    "plt.ylabel(\"Similarity of answers\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"{sum([1 for i in comparison if i == 1])/len(comparison) * 100} % predictions correct by both models.\")\n",
    "print(f\"{sum([1 for i in comparison if i == 0.5])/len(comparison) * 100} % predictions correct by only one model.\")\n",
    "print(f\"{sum([1 for i in comparison if i == 0])/len(comparison) * 100} % predictions incorrect by both models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa9f1e",
   "metadata": {},
   "source": [
    "Looking at the questions it looks like the sentences are ambiguous and could easily be mistaken by different language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "29a0201a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was furnished partly as a sitting and partly as a bedroom , with flowers arranged _____ in every nook and corner.'\n",
      " 'daintily' 'privately' 'inadvertently' 'miserably' 'comfortably']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: c\n",
      "\n",
      "['There is no _____ between them , but they all open out into the same corridor.'\n",
      " 'understanding' 'communication' 'difference' 'intrigue' 'issue']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: b\n",
      "\n",
      "['I can distinctly remember that as we did so there came three _____ from a neighboring clock.'\n",
      " 'batters' 'cheers' 'centuries' 'fiddlers' 'chimes']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['You can imagine my _____ , Watson , when within two inches of my peg I saw a conical depression in the ground.'\n",
      " 'virtue' 'seamanship' 'occupation' 'exultation' 'ankles']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['Was he our _____ enemy , or was he by chance our guardian angel.'\n",
      " 'consecrated' 'pedantic' 'malignant' 'cheerful' 'splendid']\n",
      "BERT: 0\n",
      "RoBERTa: 4\n",
      "Correct answer: e\n",
      "\n",
      "['He lay back without _____ , though he bit his lip from time to time.'\n",
      " 'ceremony' 'control' 'pity' 'wincing' 'enthusiasm']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: a\n",
      "\n",
      "['He actually sat _____ in an arm-chair , and I could hardly get him to speak coherently.'\n",
      " 'adrift' 'smiling' 'comfortably' 'crying' 'sewing']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: c\n",
      "\n",
      "['I sat down upon a _____ in the corner and thought the whole matter carefully over.'\n",
      " 'keg' 'sword' 'farm' 'fly' 'needle']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "['His hair and whiskers were shot with gray , and his face was all crinkled and _____ like a withered apple.'\n",
      " 'chattering' 'picturesque' 'hopeful' 'puckered' 'glistening']\n",
      "BERT: 4\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['Sherlock Holmes stopped at a door some little distance from the Carlton , and , _____ me not to speak , he led the way into the hall.'\n",
      " 'pulling' 'cautioning' 'addressing' 'touching' 'approaching']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: c\n",
      "\n",
      "['Then he _____ himself in his chair and looked them over with a gleam of satisfaction in his eyes.'\n",
      " 'mopped' 'reseated' 'lashed' 'shut' 'committed']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['Already I was unable to stand erect , when my eye caught something which brought a _____ of hope back to my heart.'\n",
      " 'variety' 'gush' 'bunch' 'pair' 'branch']\n",
      "BERT: 4\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['He said a few words to each candidate as he came up , and then he always managed to find some fault in them which would _____ them.'\n",
      " 'teach' 'join' 'disqualify' 'hinder' 'mock']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: a\n",
      "\n",
      "['Perhaps , Mr. Wilson , you would have the great kindness to _____ your narrative.'\n",
      " 'outlast' 'reward' 'recommence' 'interrupt' 'spoil']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: b\n",
      "\n",
      "['We had reached the same crowded _____ in which we had found ourselves in the morning.'\n",
      " 'creek' 'sepulchre' 'thoroughfare' 'clergy' 'theatres']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['Presently he emerged , looking even more _____ than before.' 'numerous'\n",
      " 'unprofitable' 'instructive' 'flurried' 'reassuring']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: e\n",
      "\n",
      "['There was something that touched me as I read this letter , something _____ in the reiterated appeals to bring Holmes.'\n",
      " 'naked' 'substantial' 'egotistic' 'pitiable' 'mysterious']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: c\n",
      "\n",
      "['Between your brandy and your _____ , I feel a new man.' 'distress'\n",
      " 'bandage' 'innocence' 'permission' 'oaths']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['It was quite certain that he had _____ his fate , and that it had caused him the utmost horror.'\n",
      " 'resumed' 'pawned' 'foreseen' 'mislaid' 'improved']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: d\n",
      "\n",
      "['With much labour we separated them and carried him , living but horribly _____ , into the house.'\n",
      " 'good-natured' 'mangled' 'well-spoken' 'intelligent' 'unchristian']\n",
      "BERT: 2\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['There is something in it which _____ me extremely.' 'befel' 'possesses'\n",
      " 'employs' 'fed' 'fascinates']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: b\n",
      "\n",
      "['But , first , as I am rather shaken by the knocking about which I had in the dressing-room , I think that I shall help myself to a _____ of your brandy , Colonel.'\n",
      " 'lump' 'dash' 'bar' 'picture' 'piece']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['Is that a place where a _____ would be likely to take his station.'\n",
      " 'Canadian' 'breeze' 'creature' 'government' 'shepherd']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: a\n",
      "\n",
      "['A small taper on the edge of the table shed a feeble light which _____ to show me that he was fully dressed.'\n",
      " 'ascended' 'goes' 'sprang' 'stooped' 'sufficed']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: e\n",
      "\n",
      "[\"It's not been _____ for two days.\" 'built' 'slain' 'invaluable' 'formed'\n",
      " 'fed']\n",
      "BERT: 2\n",
      "RoBERTa: 0\n",
      "Correct answer: d\n",
      "\n",
      "['It contained a loaf of bread , a tinned tongue , and two _____ of preserved peaches.'\n",
      " 'pairs' 'books' 'bottles' 'drops' 'tins']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['I gave a _____ myself.' 'trifle' 'coward' 'hurry' 'kitchen' 'rock']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: c\n",
      "\n",
      "['On reaching Scotland Yard , however , it was more than an hour before we could get Inspector Gregson and comply with the legal _____ which would enable us to enter the house.'\n",
      " 'obstacles' 'acuteness' 'formalities' 'disputes' 'restraints']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['These articles , with two small _____ chairs , made up all the furniture in the room save for a square of Wilton carpet in the centre.'\n",
      " 'wine' 'wicker-work' 'lighted' 'walking' 'massive']\n",
      "BERT: 0\n",
      "RoBERTa: 3\n",
      "Correct answer: e\n",
      "\n",
      "['Indeed , it was almost _____ , the effect which this giggling ruffian had produced upon the unfortunate linguist , for he could not speak of him save with trembling hands and a blanched cheek.'\n",
      " 'mesmeric' 'humdrum' 'unfounded' 'pedestrian' 'deferential']\n",
      "BERT: 2\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['It was the most _____ position in which I ever found myself in my life , and it was the thought of it that started me laughing just now.'\n",
      " 'horrible' 'dangerous' 'degrading' 'preposterous' 'important']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: e\n",
      "\n",
      "['The matter was so _____ that it is my belief that they brought with them some sort of block or pulley which might serve as a gallows.'\n",
      " 'bewildered' 'dumfounded' 'prearranged' 'astonished' 'intense']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: d\n",
      "\n",
      "['I stared at it _____ , not knowing what was about to issue from it.'\n",
      " 'rapidly' 'horror-stricken' 'forever' 'afterwards' 'lightly']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['Her rich _____ made the white face of her companion the more worn and haggard by the contrast.'\n",
      " 'leaves' 'tints' 'armor' 'cloth' 'sauce']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['Who were these German people , and what were they doing living in this strange , _____ place.'\n",
      " 'infallible' 'impossible' 'out-of-the-way' 'unladylike' 'untimely']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['He is not a bad fellow , though an absolute _____ in his profession.'\n",
      " 'difficulty' 'faith' 'experience' 'contradiction' 'imbecile']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: b\n",
      "\n",
      "['He came himself to live with me in the character of a _____ patient.'\n",
      " 'resident' 'prompt' 'wealthy' 'timid' 'speculative']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['You may believe , then , that I was in my _____ when , at the appointed hour , the page showed in the patient.'\n",
      " 'school' 'consulting-room' 'memory' 'baggage' 'childhood']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: b\n",
      "\n",
      "['It was a _____ little room , with a low ceiling and a gaping fireplace , after the fashion of old country-houses.'\n",
      " 'good-humoured' 'quick' 'regular' 'homely' 'witty']\n",
      "BERT: 0\n",
      "RoBERTa: 2\n",
      "Correct answer: b\n",
      "\n",
      "['Sherlock Holmes and I had no difficulty in _____ a bedroom and sitting-room at the Crown Inn.'\n",
      " 'inventing' 'engaging' 'digging' 'erecting' 'opening']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: a\n",
      "\n",
      "['Why should she fight against every _____ until it was forced from her.'\n",
      " 'taste' 'job' 'admission' 'coast' 'experiment']\n",
      "BERT: 0\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['Still , of course , if you would like to _____ out of the business , there is plenty of time to do so.'\n",
      " 'linger' 'sing' 'draw' 'hang' 'wear']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: e\n",
      "\n",
      "['Not another sound broke the heavy silence of the _____ night.' 'flat'\n",
      " 'clearest' 'windless' 'breathing' 'nearest']\n",
      "BERT: 1\n",
      "RoBERTa: 0\n",
      "Correct answer: b\n",
      "\n",
      "[\"The woman's story hung coherently together , and all my _____ were unable to shake it.\"\n",
      " 'troubles' 'questions' 'senses' 'limbs' 'clothes']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['The firemen had been much _____ at the strange arrangements which they had found within , and still more so by discovering a newly severed human thumb upon a window-sill of the second floor.'\n",
      " 'relieved' 'thwarted' 'amused' 'perturbed' 'flattered']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "[\"Too large for easy _____ about a woman's dress.\" 'familiarity'\n",
      " 'concealment' 'conversation' 'traveling' 'confidences']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['Finally he took the _____ in his hand and gave it a brisk tug.'\n",
      " 'bell-rope' 'hole' 'reins' 'key' 'document']\n",
      "BERT: 2\n",
      "RoBERTa: 3\n",
      "Correct answer: b\n",
      "\n",
      "['I was the only passenger who got out there , and there was no one upon the platform save a single sleepy _____ with a lantern.'\n",
      " 'elm-tree' 'waiter' 'porter' 'peon' 'audience']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['Well , there is nothing very _____ in all this.' 'faint' 'limited'\n",
      " 'instructive' 'unfrequent' 'punctual']\n",
      "BERT: 1\n",
      "RoBERTa: 0\n",
      "Correct answer: c\n",
      "\n",
      "['Sitting in the _____ I more than once heard the sound of voices raised , and I had a pretty good idea what the point was which was under discussion.'\n",
      " 'fortune' 'billiard-room' 'future' 'summer' 'cradle']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: c\n",
      "\n",
      "['I caught a glimpse of rushing figures , and a moment later the voice of Holmes from within _____ them that it was a false alarm.'\n",
      " 'leaving' 'studying' 'supporting' 'assuring' 'regarding']\n",
      "BERT: 2\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['They were _____ by a confederate inside the house.' 'defeated'\n",
      " 'astonished' 'terrified' 'accelerated' 'admitted']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: b\n",
      "\n",
      "['We found Holmes pacing up and down in the field , his chin sunk upon his _____ , and his hands thrust into his trousers pockets.'\n",
      " 'breast' 'throne' 'knees' 'pedestal' 'haunches']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['The machine goes readily enough , but there is some stiffness in the _____ of it , and it has lost a little of its force.'\n",
      " 'fervour' 'shape' 'majesty' 'habit' 'working']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['It had set , according to their account , into the most _____ expression of fear and horror which a human countenance is capable of assuming.'\n",
      " 'delicate' 'sublime' 'genteel' 'tender' 'dreadful']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['The wind was howling outside , and the rain was beating and _____ against the windows.'\n",
      " 'splashing' 'splitting' 'leaping' 'staggering' 'growing']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['Had he observed a _____ the night before waiting for me.' 'vision'\n",
      " 'picture' 'nerve' 'hound' 'carriage']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['Now , there is no one more easy to _____ than a schoolmaster.'\n",
      " 'exaggerate' 'contemplate' 'improve' 'trace' 'guess']\n",
      "BERT: 1\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['She was never , as I think I have said , ostentatiously _____ , but she was heard by the coachman chatting with the Colonel in a friendly fashion.'\n",
      " 'melancholy' 'handsome' 'affectionate' 'organised' 'wounded']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['He looked round him with a _____ and stealthy air , as one who dreads pursuit.'\n",
      " 'greedy' 'calm' 'furtive' 'simple' 'sweet']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: e\n",
      "\n",
      "['I was just _____ whether I should run for it , or whether I should perch behind her landau when a cab came through the street.'\n",
      " 'commencing' 'learning' 'hearing' 'wishing' 'balancing']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: e\n",
      "\n",
      "['Far away came the sharp _____ of a boot striking upon a stone.' 'pangs'\n",
      " 'edge' 'murmur' 'clink' 'cries']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "['A vague feeling of _____ began to steal over me.' 'novelty' 'fellowship'\n",
      " 'security' 'uneasiness' 'humanity']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['I fainted when it was done , and I think that I must have been _____ for a long time.'\n",
      " 'preparing' 'senseless' 'watching' 'spoilt' 'mistaken']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['Such an _____ could not be kept secret.' 'innocence' 'earthquake' 'owl'\n",
      " 'excursion' 'artist']\n",
      "BERT: 4\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['Out of this landing opened the _____ and several bedrooms , including those of Mr. Cunningham and his son.'\n",
      " 'drawing-room' 'envelope' 'night-gown' 'valise' 'saddle']\n",
      "BERT: 2\n",
      "RoBERTa: 1\n",
      "Correct answer: b\n",
      "\n",
      "['There are many men in London , you know , who , some from _____ , some from misanthropy , have no wish for the company of their fellows.'\n",
      " 'shipboard' 'shyness' 'carelessness' 'reality' 'Greenwich']\n",
      "BERT: 2\n",
      "RoBERTa: 3\n",
      "Correct answer: b\n",
      "\n",
      "['For all they cared it might have been me , instead of my _____ , which these rascals burned at the stake.'\n",
      " 'thimble' 'effigy' 'lodging' 'childhood' 'chest']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: d\n",
      "\n",
      "['I have no doubt at all that a family _____ can be traced in these two specimens of writing.'\n",
      " 'farm' 'mannerism' 'possession' 'ghost' 'surgeon']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: d\n",
      "\n",
      "['I thought of the convict out upon the bleak , cold , _____ moor.'\n",
      " 'dazzling' 'shelterless' 'fragrant' 'fishy' 'irremediable']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: d\n",
      "\n",
      "['His characteristic talk , with its keen _____ of detail and subtle power of inference held me amused and enthralled.'\n",
      " 'observance' 'instincts' 'implements' 'expiation' 'presumption']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['The shock has made her _____ , but I understand that she was never very bright.'\n",
      " 'uncomfortable' 'drive' 'half-witted' 'scream' 'watch']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: d\n",
      "\n",
      "['There was nothing markedly abnormal in any of these conditions , which _____ with my former experiences.'\n",
      " 'prevailed' 'mingled' 'contrasted' 'harmonized' 'sputtered']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['But sometimes a letter may be _____ even when burned.' 'enjoyed'\n",
      " 'divided' 'confident' 'legible' 'disentangled']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: e\n",
      "\n",
      "['The freckles started out on the _____ face.' 'slightest' \"lady's\"\n",
      " 'Federal' 'mountain' 'outer']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['The King may do what he will without _____ from one whom he has cruelly wronged.'\n",
      " 'passing' 'hurrying' 'hindrance' 'flinching' 'moving']\n",
      "BERT: 3\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['He was deadly pale and terribly _____ , with the protruding , brilliant eyes of a man whose spirit was greater than his strength.'\n",
      " 'impromptu' 'emaciated' 'prudish' 'headless' 'profane']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: d\n",
      "\n",
      "['The thieves _____ the library and got very little for their pains.'\n",
      " 'ruled' 'ransacked' 'identified' 'enjoyed' 'visited']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: c\n",
      "\n",
      "['It is _____ that this fellow could have made two such vindictive enemies as these appear to be without knowing of it.'\n",
      " 'plain' 'likely' 'conjectured' 'inconceivable' 'probable']\n",
      "BERT: 4\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['No one could pass these _____ if they were bolted.' 'subjects'\n",
      " 'shutters' 'flowers' 'objects' 'letters']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['It was evident that a _____ or strong knife had been thrust in , and the lock forced back with it.'\n",
      " 'chisel' 'lord' 'frigate' 'nurse' 'barrel']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['Ferguson appeared to be a _____ and silent man , but I could see from the little that he said that he was at least a fellow-countryman.'\n",
      " 'captive' 'useful' 'prince' 'novel' 'morose']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "['It is to _____ you for any inconvenience that we are paying to you , a young and unknown man , a fee which would buy an opinion from the very heads of your profession.'\n",
      " 'recompense' 'befall' 'allow' 'convince' 'restore']\n",
      "BERT: 1\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['Suddenly , amid all the _____ of the gale , there burst forth the wild scream of a terrified woman.'\n",
      " 'lassitude' 'thunders' 'risk' 'glow' 'hubbub']\n",
      "BERT: 1\n",
      "RoBERTa: 2\n",
      "Correct answer: c\n",
      "\n",
      "['The ejaculation had been drawn from my companion by the fact that our door had been suddenly _____ open , and that a huge man had framed himself in the aperture.'\n",
      " 'stepped' 'whisked' 'dragged' 'staggered' 'dashed']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "['I dressed hurriedly , for I knew by experience that railway _____ were seldom trivial , and hastened downstairs.'\n",
      " 'trains' 'passengers' 'carriages' 'trials' 'cases']\n",
      "BERT: 1\n",
      "RoBERTa: 0\n",
      "Correct answer: e\n",
      "\n",
      "['What passion of hatred can it be which leads a man to _____ in such a place at such a time.'\n",
      " 'luxuriate' 'wiggle' 'dine' 'lurk' 'grow']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: d\n",
      "\n",
      "['Then suddenly he plunged forward , _____ my hand , and congratulated me warmly on my success.'\n",
      " 'scraped' 'wrung' 'remembering' 'ate' 'poked']\n",
      "BERT: 3\n",
      "RoBERTa: 4\n",
      "Correct answer: a\n",
      "\n",
      "['She then called for Miss Morrison , a young lady who lives in the next _____ , and the two went off together to their meeting.'\n",
      " 'verse' 'villa' 'century' 'generation' 'month']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: a\n",
      "\n",
      "['I could see that she was pretty , and from the gloss with which the light shone upon her dark _____ I knew that it was a rich material.'\n",
      " 'forehead' 'skin' 'eyebrows' 'dress' 'dishes']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: e\n",
      "\n",
      "['I had _____ and was scraping at this to see exactly what it was when I heard a muttered exclamation in German and saw the cadaverous face of the colonel looking down at me.'\n",
      " 'studied' 'waited' 'stooped' 'breakfasted' 'sprouted']\n",
      "BERT: 3\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "['I knew that it was my _____ voice.' 'unreasonable' 'mightier' \"sister's\"\n",
      " 'weak' 'gambling']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['In the evening I put on my waterproof and I walked far upon the _____ moor , full of dark imaginings , the rain beating upon my face and the wind whistling about my ears.'\n",
      " 'nearest' 'tall' 'polished' 'sodden' 'important']\n",
      "BERT: 0\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "['I lounged up the side aisle like any other _____ who has dropped into a church.'\n",
      " 'idler' 'emperor' 'barber' 'aunt' 'minister']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: a\n",
      "\n",
      "['But we have more _____ reasons than that for supposing it.' 'wearisome'\n",
      " 'assured' 'moral' 'liberal' 'Pagan']\n",
      "BERT: 2\n",
      "RoBERTa: 3\n",
      "Correct answer: a\n",
      "\n",
      "['But the girl held true to me , and it seemed that I would have had her when the _____ broke out , and all hell was loose in the country.'\n",
      " 'clouds' 'moon' 'storm' 'ape-man' 'Mutiny']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['It was almost dark before we found ourselves in Pall Mall , at the _____ of Mr. Melas.'\n",
      " 'rooms' 'bottom' 'edge' 'shades' 'facade']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "[\"As I ran down the passage , my sister's door was unlocked , and _____ slowly upon its hinges.\"\n",
      " 'bent' 'paced' 'beamed' 'stared' 'revolved']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['It was an old _____ door and gave at once before our united strength.'\n",
      " 'tartan' 'iron' 'convent' 'rickety' 'gray']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['His secret was a shameful one , and he could not bring himself to _____ it.'\n",
      " 'forget' 'dispel' 'enable' 'exercise' 'divulge']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: b\n",
      "\n",
      "['And into her _____ , which was the very room which I suspected.' 'hut'\n",
      " 'list' 'lap' 'pocket' 'sitting-room']\n",
      "BERT: 0\n",
      "RoBERTa: 3\n",
      "Correct answer: b\n",
      "\n",
      "['As it was , he suffered a long term of imprisonment and afterwards returned to England a _____ and disappointed man.'\n",
      " 'morose' 'shrewd' 'brave' 'surprising' 'nobler']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['It was only after a painful and prolonged scene that she was _____ by the butler and the footman.'\n",
      " 'ejected' 'consumed' 'awakened' 'startled' 'softened']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['While there she had met a young man named Harold Latimer , who had acquired an _____ over her and had eventually persuaded her to fly with him.'\n",
      " 'ascendancy' 'opprobrium' 'aurora' 'animosity' 'existence']\n",
      "BERT: 2\n",
      "RoBERTa: 3\n",
      "Correct answer: a\n",
      "\n",
      "['He was a man of singular habits , _____ company and very seldom going out.'\n",
      " 'discovering' 'shunning' 'providing' 'biting' 'keeping']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['He appeared to be _____ , for he carried his head low and walked with his knees bent.'\n",
      " 'honest' 'gay' 'cheery' 'asleep' 'deformed']\n",
      "BERT: 3\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['Luck had been against us again and again in this _____ , but now at last it came to my aid.'\n",
      " 'inquiry' 'hall' 'century' 'coach' 'mood']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['I rose and examined carefully the different _____ of wood which were scattered round the floor.'\n",
      " 'points' 'stages' 'symptoms' 'billets' 'degrees']\n",
      "BERT: 4\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['It was a _____ thing to be in the power of this spiteful old busybody.'\n",
      " 'serious' 'sweet' 'delightful' 'pleasant' 'wise']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: d\n",
      "\n",
      "['God help those who wander into the great _____ now , for even the firm uplands are becoming a morass.'\n",
      " 'cheer' 'pulpit' 'ocean' 'stair' 'mire']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['The furniture was scattered about in every direction , with dismantled shelves and open drawers , as if the lady had hurriedly _____ them before her flight.'\n",
      " 'taught' 'assigned' 'ransacked' 'warned' 'rebuked']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "[\"Sorry to see that you've had the British _____ in the house.\" 'workman'\n",
      " 'Museum' 'abode' 'Empire' 'island']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: b\n",
      "\n",
      "['I shall call with the King _____ , and with you , if you care to come with us.'\n",
      " 'yesterday' 'summer' 'gift' 'to-morrow' 'rarity']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: d\n",
      "\n",
      "['I came in by train this morning , and on _____ at Paddington as to where I might find a doctor , a worthy fellow very kindly escorted me here.'\n",
      " 'inquiring' 'exhibition' 'deck' 'arriving' 'duty']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: a\n",
      "\n",
      "['At last she looked up with something _____ and defiant in her manner.'\n",
      " 'pallid' 'warm' 'jovial' 'reckless' 'solid']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: e\n",
      "\n",
      "['It was the same good friend whose warning I had so _____ rejected.'\n",
      " 'strangely' 'nobly' 'foolishly' 'lingeringly' 'accurately']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: e\n",
      "\n",
      "['I have only one other incident to record upon this _____ and melancholy day.'\n",
      " 'obedient' 'tempestuous' 'quaint' 'excellent' 'smirking']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "['I rushed _____ from the room on to the landing.' 'forever' 'correctly'\n",
      " 'madly' 'laudably' 'gently']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['Half a _____ if you do it in twenty minutes.' 'pinch' 'guinea' 'trade'\n",
      " 'farthing' 'mile']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['This must be the _____ where the stranger lurked.' 'dishes'\n",
      " 'conversation' 'difference' 'orchestra' 'burrow']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "[\"When I saw him that afternoon so enwrapped in the _____ at St. James's Hall I felt that an evil time might be coming upon those whom he had set himself to hunt down.\"\n",
      " 'music' 'store-room' 'shadows' 'stream' 'doorway']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: d\n",
      "\n",
      "['In normal cases one can place a man in his true _____ with tolerable confidence.'\n",
      " 'biography' 'operations' 'decade' 'displacement' 'contention']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['Again and again I _____ her , but I could never get past that point.'\n",
      " 'understood' 'finished' 'deemed' 'liked' 'cross-questioned']\n",
      "BERT: 1\n",
      "RoBERTa: 3\n",
      "Correct answer: e\n",
      "\n",
      "['All you have to do is just to _____ out your chair in the consulting-room.'\n",
      " 'shut' 'blow' 'pick' 'wear' 'sweep']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: b\n",
      "\n",
      "['As he _____ from the hook it was exaggerated and intensified until he was scarce human in his appearance.'\n",
      " 'sailed' 'emerged' 'dangled' 'collected' 'issued']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['As to reward , my profession is its own reward ; but you are at liberty to _____ whatever expenses I may be put to , at the time which suits you best.'\n",
      " 'eat' 'support' 'mention' 'buy' 'defray']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['Besides , I knew that my _____ was a good man , and that he would see to anything that turned up.'\n",
      " 'mistress' 'assistant' 'estate' 'fate' 'grandmother']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: b\n",
      "\n",
      "['That cold , _____ , ironical voice could belong to but one man in all the world.'\n",
      " 'self-contained' 'incisive' 'serene' 'inflexible' 'hungry']\n",
      "BERT: 2\n",
      "RoBERTa: 4\n",
      "Correct answer: d\n",
      "\n",
      "['My heart is _____ already since I have confided my trouble to you.'\n",
      " 'punished' 'falling' 'distressed' 'soaring' 'lightened']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: b\n",
      "\n",
      "['My clothes were all _____ with dew , and my coat-sleeve was drenched with blood from my wounded thumb.'\n",
      " 'packed' 'charged' 'supplied' 'tattered' 'sodden']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: c\n",
      "\n",
      "['His aversion to women and his disinclination to form new friendships were both typical of his _____ character , but not more so than his complete suppression of every reference to his own people.'\n",
      " 'frightful' 'charming' 'princely' 'graceful' 'unemotional']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['He was all right , as far as money went , but in his _____ he had given her what looked like a bad florin.'\n",
      " 'deposit' 'lifetime' 'pocket' 'temperament' 'throat']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['They inherit _____ blood by direct descent , and Tudor on the distaff side.'\n",
      " 'antique' \"everybody's\" 'second-rate' 'Plantagenet' 'mortal']\n",
      "BERT: 2\n",
      "RoBERTa: 4\n",
      "Correct answer: a\n",
      "\n",
      "['The unknown might be lurking there , or he might be _____ on the moor.'\n",
      " 'counted' 'written' 'prowling' 'arranged' 'inflicted']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: a\n",
      "\n",
      "['From north , south , east , and west every man who had a shade of red in his hair had _____ into the city to answer the advertisement.'\n",
      " 'slipped' 'crept' 'sprung' 'tramped' 'rolled']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: c\n",
      "\n",
      "['It will end in my being _____ into the house.' 'sewed' 'rotted'\n",
      " 'entrusted' 'conveyed' 'blown']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: e\n",
      "\n",
      "['Mr. Alec stopped to see if he could help the dying man , and so the _____ got clean away.'\n",
      " 'connection' 'devil' 'villain' 'jug' 'baby']\n",
      "BERT: 1\n",
      "RoBERTa: 1\n",
      "Correct answer: c\n",
      "\n",
      "['I rushed forward , fell down , clapped my hand to my face , and became a _____ spectacle.'\n",
      " 'concrete' 'mathematical' 'distant' 'piteous' 'romantic']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['The paper over each window was _____ to light , and a blue curtain was drawn across the glass work in front.'\n",
      " 'wonderful' 'averse' 'prepared' 'disproportionate' 'impenetrable']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: a\n",
      "\n",
      "[\"I was feeling _____ and stupid , partly from my dinner and also from the effects of a long day's work.\"\n",
      " 'shrewd' 'drowsy' 'cynical' 'lonely' 'powerful']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: c\n",
      "\n",
      "[\"Don't you dare to _____ with my affairs.\" 'dance' 'meddle' 'dine'\n",
      " 'remain' 'fight']\n",
      "BERT: 4\n",
      "RoBERTa: 4\n",
      "Correct answer: d\n",
      "\n",
      "['During my _____ I had been intimately associated with a lad named Percy Phelps , who was of much the same age as myself , though he was two classes ahead of me.'\n",
      " 'absence' 'school-days' 'wake' 'dreams' 'trip']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: e\n",
      "\n",
      "['He loved to lie in the very centre of five millions of people , with his _____ stretching out and running through them , responsive to every little rumor or suspicion of unsolved crime.'\n",
      " 'filaments' 'manuscript' 'horn' 'neck' 'fleet']\n",
      "BERT: 3\n",
      "RoBERTa: 3\n",
      "Correct answer: e\n",
      "\n",
      "['The incidents of the next few days are _____ graven upon my recollection , and I can tell them without reference to the notes made at the time.'\n",
      " 'probably' 'indelibly' 'creatures' 'doubtless' 'nowadays']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: b\n",
      "\n",
      "['It told how two _____ who had been traveling with a woman had met with a tragic end.'\n",
      " 'voices' 'cuckoos' 'ghosts' 'Englishmen' 'nations']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: c\n",
      "\n",
      "['It is most _____ unusual.' 'instantly' 'severely' 'frequently'\n",
      " 'eminently' 'refreshingly']\n",
      "BERT: 2\n",
      "RoBERTa: 1\n",
      "Correct answer: d\n",
      "\n",
      "['Mr. Jabez Wilson started up in his chair , with his _____ upon the paper , but his eyes upon my companion.'\n",
      " 'poem' 'forefinger' 'tobacco' 'judgment' 'dogs']\n",
      "BERT: 2\n",
      "RoBERTa: 2\n",
      "Correct answer: e\n",
      "\n",
      "['It was a quarter to ten before we reached London Bridge , and half past before the four of us _____ on the Beckenham platform.'\n",
      " 'rolled' 'dined' 'fed' 'alighted' 'seized']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: c\n",
      "\n",
      "['Our visitor bore every mark of being an average commonplace British tradesman , obese , _____ , and slow.'\n",
      " 'blind' 'energetic' 'eloquent' 'pompous' 'sandy-haired']\n",
      "BERT: 0\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n",
      "['It is your commonplace , _____ crimes which are really puzzling , just as a commonplace face is the most difficult to identify.'\n",
      " 'underlying' 'featureless' 'theological' 'flattering' 'inevitable']\n",
      "BERT: 3\n",
      "RoBERTa: 0\n",
      "Correct answer: a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(comparison):\n",
    "    if j == 0:\n",
    "        print(test_data.values[i])\n",
    "        print(f\"BERT: {np.argmax(bert[i])}\")\n",
    "        print(f\"RoBERTa: {np.argmax(roberta[i])}\")\n",
    "        print(f\"Correct answer: {test_answer[i]}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef544148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
